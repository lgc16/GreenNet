{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 此程序用来求解正方形上Helmholtz方程的格林函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "1.6.0+cu101\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable as v\n",
    "import scipy.special as scp\n",
    "\n",
    "is_gpu = torch.cuda.is_available()\n",
    "if is_gpu:\n",
    "    id = 0\n",
    "    torch.cuda.set_device(id)\n",
    "    \n",
    "#gpu_nums = torch.cuda.device_count()\n",
    "#gpu_index = torch.cuda.current_device()\n",
    "#print(is_gpu,gpu_nums,gpu_index)\n",
    "device = torch.device('cuda' if is_gpu else 'cpu')\n",
    "\n",
    "device = torch.device('cpu')\n",
    "print(device)\n",
    "torch.set_default_tensor_type('torch.DoubleTensor')\n",
    "print(torch.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置多边形区域和边界上的节点和边界条件 设置积分矩阵\n",
    "# vertex_num  多边形边数\n",
    "# vertex      多边形顶点（按逆时针连接）\n",
    "# M           在每条边上取的样本点数\n",
    "# normal      样本点处的外法向量\n",
    "# h           每条边上两点间的距离\n",
    "# sample_num  总样本点数即 每条边上样本点数*多边形顶点数\n",
    "# sample_x    样本点坐标\n",
    "# k           波数\n",
    "\n",
    "# G2_r        基本解的外法向导数的实部\n",
    "# G2_i        基本解的外法向导数的虚部\n",
    "# A2_r        积分矩阵的实部\n",
    "# A2_i        积分矩阵的虚部\n",
    "\n",
    "# in_xy       网络的输入即(x,y)两点的product\n",
    "# sample_u_r  边界条件的实部\n",
    "# sample_u_i  边界条件的虚部\n",
    "\n",
    "k=1\n",
    "M = 50\n",
    "line = (torch.linspace(0,1-1/M,M)).reshape(-1,1)\n",
    "vertex_num = 4\n",
    "vertex = torch.Tensor([[-1,-1],[1,-1],[1,1],[-1,1],[-1,-1]])\n",
    "\n",
    "rot = torch.Tensor([[0,-1],[1,0]])  #顺时针旋转90度\n",
    "\n",
    "normal = torch.zeros(vertex_num,2)  #各边法向量\n",
    "h = torch.zeros(vertex_num,1)     #各边小区间单位长度\n",
    "for i in range(vertex_num):\n",
    "    normal[i,:] = (vertex[i+1,:]-vertex[i,:])@rot\n",
    "    normal[i,:] = normal[i,:]/(normal[i,:].norm())\n",
    "    h[i] = (vertex[i+1,:]-vertex[i,:]).norm()/M\n",
    "\n",
    "sample_num = vertex_num*M\n",
    "sample_x = torch.zeros(vertex_num*M,2)\n",
    "for i in range(vertex_num):\n",
    "    sample_x[i*M:i*M+M,:] = vertex[i,:]+(vertex[i+1,:]-vertex[i,:])*line\n",
    "sample_u = torch.zeros(sample_num,1)\n",
    "\n",
    "G2_r = torch.zeros(sample_num,sample_num)\n",
    "G2_i = torch.zeros(sample_num,sample_num)\n",
    "for i in range(sample_num):\n",
    "    for j in range(sample_num):\n",
    "        d = sample_x[j,:] - sample_x[i,:]\n",
    "        r0 = d.norm()\n",
    "        j0 = int(j/M)\n",
    "        j1 = int((j-1)/M)%vertex_num\n",
    "        G2_r[i,j] = scp.hankel1(1,k*r0).imag/4*((d*normal[j0,:]*h[j0]+d*normal[j1,:]*h[j1]).sum())/2/r0*k \n",
    "        G2_i[i,j] = -scp.hankel1(1,k*r0).real/4*((d*normal[j0,:]*h[j0]+d*normal[j1,:]*h[j1]).sum())/2/r0*k \n",
    "        \n",
    "A2_r = torch.zeros(sample_num,sample_num)\n",
    "A2_i = torch.zeros(sample_num,sample_num)\n",
    "for i in range(sample_num):\n",
    "    if (i%M != 0) and (i%M != 1) and (i%M != M-1):\n",
    "        for j in range(sample_num):\n",
    "            if i==j:\n",
    "                A2_r[i,j] , A2_i[i,j] = 1/2 , 0\n",
    "            else:\n",
    "                A2_r[i,j] , A2_i[i,j] = -G2_r[i,j] , -G2_i[i,j]\n",
    "\n",
    "M0 = 120\n",
    "in_x = torch.rand(M0,2)*2-1\n",
    "int_xy = torch.zeros(M0*sample_num,4)\n",
    "for i in range(M0):\n",
    "    int_xy[i*sample_num:(i+1)*sample_num,0:2] = in_x[i,:]\n",
    "    int_xy[i*sample_num:(i+1)*sample_num,2:4] = sample_x\n",
    "sample_u_r = -scp.hankel1(0,k*(((int_xy[:,0:2]-int_xy[:,2:4])**2).sum(axis=1)).sqrt()).imag/4\n",
    "sample_u_i = scp.hankel1(0,k*(((int_xy[:,0:2]-int_xy[:,2:4])**2).sum(axis=1)).sqrt()).real/4\n",
    "for i in range(M0*vertex_num):\n",
    "    sample_u_r[i*M] , sample_u_i[i*M] = 0 , 0\n",
    "    sample_u_r[i*M+1] , sample_u_i[i*M+1] = 0 , 0\n",
    "    sample_u_r[i*M+M-1] , sample_u_i[i*M+M-1] = 0 , 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 网络结构\n",
    "\n",
    "# ResNet结构\n",
    "# m 为神经元个数\n",
    "m = 60\n",
    "class Net(nn.Module):\n",
    "  def __init__(self,m,out):\n",
    "    super(Net, self).__init__()\n",
    "    self.input = nn.Linear(4,m)\n",
    "    self.block1=nn.Sequential(\n",
    "      nn.Linear(m,m),nn.ReLU(),\n",
    "      nn.Linear(m,m),nn.ReLU(),\n",
    "    )\n",
    "    self.block2=nn.Sequential(\n",
    "      nn.Linear(m,m),nn.ReLU(),\n",
    "      nn.Linear(m,m),nn.ReLU(),\n",
    "    )\n",
    "    self.block3=nn.Sequential(\n",
    "      nn.Linear(m,m),nn.ReLU(),\n",
    "      nn.Linear(m,m),nn.ReLU(),\n",
    "    )\n",
    "    self.block4=nn.Sequential(\n",
    "      nn.Linear(m,m),nn.ReLU(),\n",
    "      nn.Linear(m,m),nn.ReLU(),\n",
    "    )\n",
    "    self.block5=nn.Sequential(\n",
    "      nn.Linear(m,m),nn.ReLU(),\n",
    "      nn.Linear(m,m),nn.ReLU(),\n",
    "    )\n",
    "    self.block6=nn.Sequential(\n",
    "      nn.Linear(m,m),nn.ReLU(),\n",
    "      nn.Linear(m,m),nn.ReLU(),\n",
    "    )\n",
    "    self.block7=nn.Sequential(\n",
    "      nn.Linear(m,m),nn.ReLU(),\n",
    "      nn.Linear(m,m),nn.ReLU(),\n",
    "    )\n",
    "    self.block8=nn.Sequential(\n",
    "      nn.Linear(m,m),nn.ReLU(),\n",
    "      nn.Linear(m,m),nn.ReLU(),\n",
    "    )\n",
    "    self.out = nn.Linear(m,out)\n",
    "  def forward(self, x):\n",
    "      x = self.input(x)\n",
    "      x = self.block1(x) + x\n",
    "      x = self.block2(x) + x\n",
    "      x = self.block3(x) + x\n",
    "      x = self.block4(x) + x\n",
    "      x = self.block5(x) + x\n",
    "      x = self.block6(x) + x\n",
    "      x = self.block7(x) + x\n",
    "      x = self.block8(x) + x\n",
    "      x = self.out(x)\n",
    "      return x\n",
    "\n",
    "net1 = Net(m,2) #用格林函数形式作为损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss, epoch: 38.387561366955836 0\n",
      "loss, epoch: 0.6338183372392864 100\n"
     ]
    }
   ],
   "source": [
    "#训练过程\n",
    "\n",
    "# optimizer   优化器\n",
    "# Epoch       总训练次数\n",
    "# int_h_r  样本点处密度函数值h(x)的实部\n",
    "# int_h_i  样本点处密度函数值h(x)的虚部\n",
    "# u0_r        样本点处格林函数数值解实部\n",
    "# u0_i        样本点处格林函数数值解虚部\n",
    "optimizer = torch.optim.Adam(net1.parameters(net1),lr=0.0001)\n",
    "Epoch = 100\n",
    "loss_all = np.zeros(Epoch+1)\n",
    "u0 = torch.zeros(M0*sample_num,1)\n",
    "for epoch in range(Epoch+1):\n",
    "    loss = 0\n",
    "    \n",
    "    if (epoch)%200==0:  \n",
    "        M0 = 120\n",
    "        in_x = torch.rand(M0,2)*2-1\n",
    "        int_xy = torch.zeros(M0*sample_num,4)\n",
    "        for i in range(M0):\n",
    "            int_xy[i*sample_num:(i+1)*sample_num,0:2] = in_x[i,:]\n",
    "            int_xy[i*sample_num:(i+1)*sample_num,2:4] = sample_x\n",
    "        sample_u_r = -scp.hankel1(0,k*(((int_xy[:,0:2]-int_xy[:,2:4])**2).sum(axis=1)).sqrt()).imag/4\n",
    "        sample_u_i = scp.hankel1(0,k*(((int_xy[:,0:2]-int_xy[:,2:4])**2).sum(axis=1)).sqrt()).real/4\n",
    "        for i in range(M0*vertex_num):\n",
    "            sample_u_r[i*M] , sample_u_i[i*M] = 0 , 0\n",
    "            sample_u_r[i*M+1] , sample_u_i[i*M+1] = 0 , 0\n",
    "            sample_u_r[i*M+M-1] , sample_u_i[i*M+M-1] = 0 , 0\n",
    "        int_xy = int_xy.to(device)\n",
    "        sample_u_r = sample_u_r.to(device)\n",
    "        sample_u_i = sample_u_i.to(device) \n",
    "    \n",
    "    int_h_r,int_h_i = net1(int_xy)[:,0] , net1(int_xy)[:,1]#这个方法甚至不需要内部点\n",
    "    for i in range(M0):\n",
    "        u0_r = A2_r@(int_h_r[i*sample_num:(i+1)*sample_num])-A2_i@(int_h_i[i*sample_num:(i+1)*sample_num])\n",
    "        u0_i = A2_i@(int_h_r[i*sample_num:(i+1)*sample_num])+A2_r@(int_h_i[i*sample_num:(i+1)*sample_num])\n",
    "        loss = loss + torch.mean(torch.pow(u0_r-sample_u_r[i*sample_num:(i+1)*sample_num],2)+torch.pow(u0_i-sample_u_i[i*sample_num:(i+1)*sample_num],2))\n",
    "            \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    loss_all[epoch] = loss.cpu().detach().numpy() \n",
    "    if epoch%100==0:\n",
    "        print('loss, epoch:', loss.detach().numpy(),epoch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 下面的部分是用上面求解得到的格林函数求解方程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 设置积分节点 ###\n",
    "\n",
    "# 设置积分的权重（利用高斯积分的product形式）\n",
    "int_sample_num = 20 \n",
    "h0 = 2/int_sample_num\n",
    "int_num = 2\n",
    "\n",
    "vertex_x = torch.Tensor([[-1,-1],[1,-1],[1,1],[-1,1]])\n",
    "\n",
    "if int_num == 2:\n",
    "    int_sample0 = torch.Tensor([[-np.sqrt(1/3)],[np.sqrt(1/3)]])\n",
    "    int_w0 = torch.Tensor([[1/2],[1/2]])\n",
    "if int_num == 3:\n",
    "    int_sample0 = torch.Tensor([[-np.sqrt(3/5)],[0],[np.sqrt(3/5)]])\n",
    "    int_w0 = torch.Tensor([[5/18],[4/9],[5/18]])\n",
    "if int_num == 4:\n",
    "    int_sample0 = torch.Tensor([[-np.sqrt(1/3)],[-np.sqrt(1/3)],[np.sqrt(1/3)],[np.sqrt(1/3)]])\n",
    "    int_w0 = torch.Tensor([[5/18],[4/9],[5/18]])\n",
    "\n",
    "#设置积分的节点\n",
    "int_sample = torch.zeros(int_sample_num*int_sample_num*int_num*int_num,2)\n",
    "int_w = torch.zeros(int_sample_num*int_sample_num*int_num*int_num,1)\n",
    "for i in range(int_sample_num):\n",
    "    for l in range(int_sample_num):\n",
    "        for j in range(int_num):\n",
    "            for s in range(int_num):\n",
    "                int_sample[i*int_sample_num*int_num*int_num+l*int_num*int_num+j*int_num+s,0] = -1 + h0*i+ int_sample0[j]*h0/2+h0/2\n",
    "                int_sample[i*int_sample_num*int_num*int_num+l*int_num*int_num+j*int_num+s,1] = -1 + h0*l+ int_sample0[s]*h0/2+h0/2\n",
    "                int_w[i*int_sample_num*int_num*int_num+l*int_num*int_num+j*int_num+s] = int_w0[j]*int_w0[s]*h0*h0\n",
    "int_sample_num = int_sample_num*int_sample_num*int_num*int_num\n",
    "                \n",
    "sample = 625\n",
    "zz = torch.linspace(-0.98,0.98,25)\n",
    "x = torch.zeros(sample,2)\n",
    "for i in range(25):\n",
    "    for j in range(25):\n",
    "        x[i*25+j,0],x[i*25+j,1] = zz[i],zz[j]\n",
    "u_r = torch.rand(sample,1)\n",
    "u_i = torch.rand(sample,1)\n",
    "xy = torch.zeros(sample*int_sample_num,4)                 ### 坐标(x,y) \n",
    "H_r = torch.zeros(sample*int_sample_num,1)                  ### 即矩阵H(x,y)\n",
    "H_i = torch.zeros(sample*int_sample_num,1)                  ### 即矩阵H(x,y)\n",
    "for i in range(sample):\n",
    "    xy[i*int_sample_num:(i+1)*int_sample_num,2:4]=int_sample\n",
    "    xy[i*int_sample_num:(i+1)*int_sample_num,0:2]=x[i,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "###  计算积分节点和边界积分点的相应的矩阵\n",
    "G2_r_in = torch.zeros(int_sample_num,sample_num)\n",
    "G2_i_in = torch.zeros(int_sample_num,sample_num)\n",
    "for i in range(int_sample_num):\n",
    "    for j in range(sample_num):\n",
    "        j0 = int(j/M)\n",
    "        j1 = int((j-1)/M)%vertex_num\n",
    "        d = sample_x[j,:]-int_sample[i,:]\n",
    "        r0 = d.norm()\n",
    "        G2_r_in[i,j] = scp.hankel1(1,k*r0).imag/4*((d*normal[j0,:]*h[j0]+d*normal[j1,:]*h[j1]).sum())/2/r0*k \n",
    "        G2_i_in[i,j] = -scp.hankel1(1,k*r0).real/4*((d*normal[j0,:]*h[j0]+d*normal[j1,:]*h[j1]).sum())/2/r0*k \n",
    "        #G2_in[i,j] = -1/(2*np.pi)*(r*normal[j0,:]*h[j0]+r*normal[j1,:]*h[j1]).sum()/(2*d*d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###  计算H(x,y)\n",
    "inxy = torch.zeros(sample_num,4)\n",
    "inxy[:,2:4] = sample_x\n",
    "for i in range(sample):\n",
    "    inxy[:,0],inxy[:,1] = x[i,0],x[i,1]\n",
    "    #sample_h = mynet1(inxy)\n",
    "    sample_h_r,sample_h_i = (mynet1(inxy)[:,0]).reshape(-1,1) , (mynet1(inxy)[:,1]).reshape(-1,1)\n",
    "    H_r[i*int_sample_num:(i+1)*int_sample_num] = -(G2_r_in@sample_h_r - G2_i_in@sample_h_i)\n",
    "    H_i[i*int_sample_num:(i+1)*int_sample_num] = -(G2_i_in@sample_h_r + G2_r_in@sample_h_i)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###   f为被积的右端项 即 -laplace u - k^2u = f\n",
    "###   此处积分计算的是 f H的积分，再加上f G_0的积分（G_0为基本解）即最后的结果\n",
    "\n",
    "f_r = (2*(int_sample[:,0]**2+int_sample[:,1]**2-2)+k*k*(1-int_sample[:,0]**2)*(1-int_sample[:,1]**2)).reshape(-1,1)\n",
    "f_i = 0\n",
    "for i in range(sample):\n",
    "    u_r[i] = (H_r[i*int_sample_num:(i+1)*int_sample_num]*f_r*int_w - H_i[i*int_sample_num:(i+1)*int_sample_num]*f_i*int_w).sum()\n",
    "    u_i[i] = (H_r[i*int_sample_num:(i+1)*int_sample_num]*f_i*int_w + H_i[i*int_sample_num:(i+1)*int_sample_num]*f_r*int_w).sum()\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7e807f9ddb0496b7851a27b2566c8810a6974b896f5c34231241c2796bf1297c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
