{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 此程序用来求解蝶形外部区域上Helmholtz方程的格林函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "1.6.0+cu101\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable as v\n",
    "import scipy.special as scp\n",
    "import time \n",
    "\n",
    "is_gpu = torch.cuda.is_available()\n",
    "if is_gpu:\n",
    "    id = 0\n",
    "    torch.cuda.set_device(id)\n",
    "    \n",
    "#gpu_nums = torch.cuda.device_count()\n",
    "#gpu_index = torch.cuda.current_device()\n",
    "#print(is_gpu,gpu_nums,gpu_index)\n",
    "device = torch.device('cuda' if is_gpu else 'cpu')\n",
    "\n",
    "#device = torch.device('cpu')\n",
    "print(device)\n",
    "torch.set_default_tensor_type('torch.DoubleTensor')\n",
    "print(torch.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置多边形区域和边界上的节点和边界条件 设置积分矩阵\n",
    "# vertex_num  多边形边数\n",
    "# vertex      多边形顶点（按逆时针连接）\n",
    "# M           在每条边上取的样本点数\n",
    "# normal      样本点处的外法向量\n",
    "# h           每条边上两点间的距离\n",
    "# sample_num  总样本点数即 每条边上样本点数*多边形顶点数\n",
    "# sample_x    样本点坐标\n",
    "# k           波数\n",
    "\n",
    "# G2_r        基本解的外法向导数的实部\n",
    "# G2_i        基本解的外法向导数的虚部\n",
    "# A2_r        积分矩阵的实部\n",
    "# A2_i        积分矩阵的虚部\n",
    "\n",
    "# in_xy       网络的输入即(x,y)两点的product\n",
    "# sample_u_r  边界条件的实部\n",
    "# sample_u_i  边界条件的虚部\n",
    "\n",
    "k = 4\n",
    "M = 200\n",
    "line = (torch.linspace(0,1-1/M,M)).reshape(-1,1)\n",
    "vertex_num = 6\n",
    "vertex = torch.Tensor([[-0.5,-0.5],[0.5,-0.5],[0,0],[0.5,0.5],[-0.5,0.5],[0,0],[-0.5,-0.5]])\n",
    "\n",
    "rot = torch.Tensor([[0,-1],[1,0]])  #顺时针旋转90度\n",
    "\n",
    "normal = torch.zeros(vertex_num,2)  #各边法向量\n",
    "h = torch.zeros(vertex_num,1)     #各边小区间单位长度\n",
    "for i in range(vertex_num):\n",
    "    normal[i,:] = (vertex[i+1,:]-vertex[i,:])@rot\n",
    "    normal[i,:] = normal[i,:]/(normal[i,:].norm())\n",
    "    h[i] = (vertex[i+1,:]-vertex[i,:]).norm()/M\n",
    "\n",
    "sample_num = vertex_num*M\n",
    "sample_x = torch.zeros(vertex_num*M,2)\n",
    "for i in range(vertex_num):\n",
    "    sample_x[i*M:i*M+M,:] = vertex[i,:]+(vertex[i+1,:]-vertex[i,:])*line\n",
    "sample_u = torch.zeros(sample_num,1)\n",
    "\n",
    "G2_r = torch.zeros(sample_num,sample_num)\n",
    "G2_i = torch.zeros(sample_num,sample_num)\n",
    "for i in range(sample_num):\n",
    "    for j in range(sample_num):\n",
    "        r = sample_x[j,:] - sample_x[i,:]\n",
    "        d = r.norm()\n",
    "        j0 = int(j/M)\n",
    "        j1 = int((j-1)/M)%vertex_num\n",
    "        G2_r[i,j] = scp.hankel1(1,k*d).imag/4*((r*normal[j0,:]*h[j0]+r*normal[j1,:]*h[j1]).sum())/2/d*k \n",
    "        G2_i[i,j] = -scp.hankel1(1,k*d).real/4*((r*normal[j0,:]*h[j0]+r*normal[j1,:]*h[j1]).sum())/2/d*k \n",
    "        \n",
    "A2_r = torch.zeros(sample_num,sample_num)\n",
    "A2_i = torch.zeros(sample_num,sample_num)\n",
    "for i in range(sample_num):\n",
    "    if (i%M != 0) and (i%M != 1) and (i%M != M-1):\n",
    "        for j in range(sample_num):\n",
    "            if i==j:\n",
    "                A2_r[i,j] , A2_i[i,j] = -1/2 , 0\n",
    "            else:\n",
    "                A2_r[i,j] , A2_i[i,j] = -G2_r[i,j] , -G2_i[i,j]\n",
    "\n",
    "M0 = 150\n",
    "in_x = torch.zeros(M0,2)\n",
    "for i in range(M0):\n",
    "    in_x0 = torch.rand(2)*2-1\n",
    "    while abs(in_x0[1]/in_x0[0])>=1 and abs(in_x0[1])<=0.5:\n",
    "        in_x0 = torch.rand(2)*2-1\n",
    "    in_x[i,:] = in_x0\n",
    "    \n",
    "int_xy = torch.zeros(M0*sample_num,4)\n",
    "for i in range(M0):\n",
    "    int_xy[i*sample_num:(i+1)*sample_num,0:2] = in_x[i,:]\n",
    "    int_xy[i*sample_num:(i+1)*sample_num,2:4] = sample_x\n",
    "sample_u_r = -scp.hankel1(0,k*(((int_xy[:,0:2]-int_xy[:,2:4])**2).sum(axis=1)).sqrt()).imag/4\n",
    "sample_u_i = scp.hankel1(0,k*(((int_xy[:,0:2]-int_xy[:,2:4])**2).sum(axis=1)).sqrt()).real/4\n",
    "for i in range(M0*vertex_num):\n",
    "    sample_u_r[i*M] , sample_u_i[i*M] = 0 , 0\n",
    "    sample_u_r[i*M+1] , sample_u_i[i*M+1] = 0 , 0\n",
    "    sample_u_r[i*M+M-1] , sample_u_i[i*M+M-1] = 0 , 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 网络结构\n",
    "\n",
    "# ResNet结构\n",
    "# m 为神经元个数\n",
    "m = 100\n",
    "class Net(nn.Module):\n",
    "  def __init__(self,m,out):\n",
    "    super(Net, self).__init__()\n",
    "    self.input = nn.Linear(4,m)\n",
    "    self.block1=nn.Sequential(\n",
    "      nn.Linear(m,m),nn.ReLU(),\n",
    "      nn.Linear(m,m),nn.ReLU(),\n",
    "    )\n",
    "    self.block2=nn.Sequential(\n",
    "      nn.Linear(m,m),nn.ReLU(),\n",
    "      nn.Linear(m,m),nn.ReLU(),\n",
    "    )\n",
    "    self.block3=nn.Sequential(\n",
    "      nn.Linear(m,m),nn.ReLU(),\n",
    "      nn.Linear(m,m),nn.ReLU(),\n",
    "    )\n",
    "    self.block4=nn.Sequential(\n",
    "      nn.Linear(m,m),nn.ReLU(),\n",
    "      nn.Linear(m,m),nn.ReLU(),\n",
    "    )\n",
    "    self.block5=nn.Sequential(\n",
    "      nn.Linear(m,m),nn.ReLU(),\n",
    "      nn.Linear(m,m),nn.ReLU(),\n",
    "    )\n",
    "    self.block6=nn.Sequential(\n",
    "      nn.Linear(m,m),nn.ReLU(),\n",
    "      nn.Linear(m,m),nn.ReLU(),\n",
    "    )\n",
    "    self.block7=nn.Sequential(\n",
    "      nn.Linear(m,m),nn.ReLU(),\n",
    "      nn.Linear(m,m),nn.ReLU(),\n",
    "    )\n",
    "    self.block8=nn.Sequential(\n",
    "      nn.Linear(m,m),nn.ReLU(),\n",
    "      nn.Linear(m,m),nn.ReLU(),\n",
    "    )\n",
    "    self.out = nn.Linear(m,out)\n",
    "  def forward(self, x):\n",
    "      x = self.input(x)\n",
    "      x = self.block1(x) + x\n",
    "      x = self.block2(x) + x\n",
    "      x = self.block3(x) + x\n",
    "      x = self.block4(x) + x\n",
    "      x = self.block5(x) + x\n",
    "      x = self.block6(x) + x\n",
    "      x = self.block7(x) + x\n",
    "      x = self.block8(x) + x\n",
    "      x = self.out(x)\n",
    "      return x\n",
    "\n",
    "net1 = Net(m,2) #用格林函数形式作为损失函数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss, epoch: 29.388771244057594 0\n",
      "loss, epoch: 1.113017897769543 100\n"
     ]
    }
   ],
   "source": [
    "#训练过程\n",
    "\n",
    "# optimizer   优化器\n",
    "# Epoch       总训练次数\n",
    "# int_h_r  样本点处密度函数值h(x)的实部\n",
    "# int_h_i  样本点处密度函数值h(x)的虚部\n",
    "# u0_r        样本点处格林函数数值解实部\n",
    "# u0_i        样本点处格林函数数值解虚部\n",
    "optimizer = torch.optim.Adam(net1.parameters(net1),lr=0.0001)\n",
    "Epoch = 100\n",
    "loss_all = np.zeros(Epoch+1)\n",
    "u0 = torch.zeros(M0*sample_num,1)\n",
    "for epoch in range(Epoch+1):\n",
    "    loss = 0\n",
    "    \n",
    "    if (epoch+1)%200==0:  \n",
    "        in_x = torch.zeros(M0,2)\n",
    "        for i in range(M0):\n",
    "            in_x0 = torch.rand(2)*2-1\n",
    "            while abs(in_x0[1]/in_x0[0])>=1 and abs(in_x0[1])<=0.5:\n",
    "                in_x0 = torch.rand(2)*2-1\n",
    "            in_x[i,:] = in_x0\n",
    "\n",
    "        int_xy = torch.zeros(M0*sample_num,4)\n",
    "        for i in range(M0):\n",
    "            int_xy[i*sample_num:(i+1)*sample_num,0:2] = in_x[i,:]\n",
    "            int_xy[i*sample_num:(i+1)*sample_num,2:4] = sample_x\n",
    "\n",
    "        sample_u_r = -scp.hankel1(0,k*(((int_xy[:,0:2]-int_xy[:,2:4])**2).sum(axis=1)).sqrt()).imag/4\n",
    "        sample_u_i = scp.hankel1(0,k*(((int_xy[:,0:2]-int_xy[:,2:4])**2).sum(axis=1)).sqrt()).real/4\n",
    "        for i in range(M0*vertex_num):\n",
    "            sample_u_r[i*M] , sample_u_i[i*M] = 0 , 0\n",
    "            sample_u_r[i*M+1] , sample_u_i[i*M+1] = 0 , 0\n",
    "            sample_u_r[i*M+M-1] , sample_u_i[i*M+M-1] = 0 , 0\n",
    "        int_xy = int_xy.to(device)\n",
    "        sample_u_r = sample_u_r.to(device)\n",
    "        sample_u_i = sample_u_i.to(device) \n",
    "    \n",
    "    int_h_r,int_h_i = net1(int_xy)[:,0] , net1(int_xy)[:,1]#这个方法甚至不需要内部点\n",
    "    for i in range(M0):\n",
    "        u0_r = A2_r@(int_h_r[i*sample_num:(i+1)*sample_num])-A2_i@(int_h_i[i*sample_num:(i+1)*sample_num])\n",
    "        u0_i = A2_i@(int_h_r[i*sample_num:(i+1)*sample_num])+A2_r@(int_h_i[i*sample_num:(i+1)*sample_num])\n",
    "        loss = loss + torch.mean(torch.pow(u0_r-sample_u_r[i*sample_num:(i+1)*sample_num],2)+torch.pow(u0_i-sample_u_i[i*sample_num:(i+1)*sample_num],2))\n",
    "        \n",
    "    \n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    loss_all[epoch] = loss.cpu().detach().numpy() \n",
    "    if epoch%100==0:\n",
    "        print('loss, epoch:', '%4.f'%loss.detach().numpy(),epoch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 通过上面的运算可以求得相应的密度函数，然后再与之前的例子一致过程可以得到求解区域任意点的H(x,y)的值"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 32-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e8c1a369db2ba82566bbfb3895fc579c21916062ea9088fb31853898b761f706"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
